{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20aaf590-0676-4f12-a5ca-89e3b3162ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 284 Âµs (started: 2025-02-19 19:51:32 +08:00)\n"
     ]
    }
   ],
   "source": [
    "#from src.retriever import Retriever\n",
    "import os,subprocess\n",
    "import sys\n",
    "sys.path.append('/root/car_sales_QA/src')\n",
    "\n",
    "from FlagEmbedding import BGEM3FlagModel,FlagReranker\n",
    "from dotenv import load_dotenv\n",
    "from LLM_utils import LLM\n",
    "from retriever import Retriever\n",
    "from utils import set_proxy\n",
    "load_dotenv()\n",
    "%load_ext autotime\n",
    "\n",
    "# result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "# output = result.stdout\n",
    "# for line in output.splitlines():\n",
    "#     if '=' in line:\n",
    "#         var, value = line.split('=', 1)\n",
    "#         os.environ[var] = value\n",
    "\n",
    "#unset http_proxy && unset https_proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19d35bca-f2e1-4ba1-8d50-b5f4d6622d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeae8230c3ac476d9216566169d7e737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.45 s (started: 2025-02-19 19:51:38 +08:00)\n"
     ]
    }
   ],
   "source": [
    "retriever = Retriever(embedder = 'BAAI/bge-m3',reranker = 'BAAI/bge-reranker-v2-m3',collection_name = 'sales_qa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70804d5-6752-4f3a-9ab8-d3361f3a6e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_id = 'ep-20250213200344-crq6r'\n",
    "#model_id = 'LLM-Research/Meta-Llama-3.1-8B-Instruct-AWQ-INT4'\n",
    "gen_llm = LLM(model_id,\n",
    "              api_key = os.getenv('ARK_API_KEY'),base_url = os.getenv('ARK_BASE_URL')\n",
    "             )\n",
    "#model_id = 'LLM-Research/Meta-Llama-3.1-8B-Instruct-AWQ-INT4'\n",
    "gen_llm('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce560172-e694-46c5-b5d6-1edba2836bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def set_proxy():\n",
    "    \n",
    "    # Run the bash command to source the network configuration and capture the proxy settings\n",
    "    result = subprocess.run(\n",
    "        'bash -c \"source /etc/network_turbo && env | grep proxy\"', \n",
    "        shell=True, capture_output=True, text=True\n",
    "    )\n",
    "\n",
    "    # Set the proxy environment variables from the command output\n",
    "    proxies = {}\n",
    "    for line in result.stdout.splitlines():\n",
    "        if '=' in line:\n",
    "            var, value = line.split('=', 1)\n",
    "            os.environ[var] = value\n",
    "            \n",
    "    # Yield control back to the block of code using the context manager\n",
    "    yield\n",
    "\n",
    "    # Restore the original proxy environment variables\n",
    "    for key, value in os.environ.items():\n",
    "        if 'proxy' in key:\n",
    "            os.environ.pop(key, None)  # Remove the key if it wasn't set originally\n",
    "with set_proxy():\n",
    "    print(1)\n",
    "proxies = {key: os.environ.get(key) for key in os.environ if 'proxy' in key.lower()}\n",
    "print(proxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba16ce2a-6400-43e1-a27d-03a7bee75af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,subprocess\n",
    "import sys\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fb06ad-24c7-4d09-bd2f-b1b81075f7b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import random\n",
    "import time\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(type=\"messages\")\n",
    "    msg = gr.Textbox()\n",
    "    clear = gr.Button(\"Clear\")\n",
    "\n",
    "    def user(user_message, history: list):\n",
    "        return \"\", history + [{\"role\": \"user\", \"content\": user_message}]\n",
    "        \n",
    "    def bot(history: list):\n",
    "        bot_message = random.choice([\"\"\"\"Hey! ðŸ˜Š Iâ€™m here to make your car-buying experience smooth and stress-free. Tell me a bit about what youâ€™re looking for, and Iâ€™ll get you started!\"\"\",\n",
    "                                    \"\"\"Hello and welcome! ðŸŽ‰ Ready to find your dream car? Let me guide you through our latest models, special offers, and financing options. What are you looking for?\"\"\",\n",
    "                                    \"\"\"\"Hey there! ðŸ‘‹ Excited to help you find the perfect car today! Whether itâ€™s something sleek, spacious, or sporty, Iâ€™ve got you covered. What kind of vehicle are you dreaming of?\"\"\"])\n",
    "        \n",
    "        history.append({\"role\": \"assistant\", \"content\": \"\"})\n",
    "        for character in bot_message:\n",
    "            history[-1]['content'] += character\n",
    "            time.sleep(0.05)\n",
    "            yield history\n",
    "\n",
    "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
    "        bot, chatbot, chatbot\n",
    "    )\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58922ded-cc10-4430-aee9-dd71e2ab513a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append('/root/data_disk/src')\n",
    "\n",
    "from retriever import Retriever\n",
    "from LLM_utils import LLM\n",
    "from prompt import generate_prompt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
