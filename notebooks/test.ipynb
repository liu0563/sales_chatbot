{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aaf590-0676-4f12-a5ca-89e3b3162ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from src.retriever import Retriever\n",
    "import os,subprocess\n",
    "import sys\n",
    "sys.path.append('/root/data_disk/src')\n",
    "\n",
    "from FlagEmbedding import BGEM3FlagModel,FlagReranker\n",
    "from dotenv import load_dotenv\n",
    "from src.LLM_utils import LLM\n",
    "from src.retriever import Retriever\n",
    "from utils import set_proxy\n",
    "load_dotenv()\n",
    "%load_ext autotime\n",
    "\n",
    "# result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "# output = result.stdout\n",
    "# for line in output.splitlines():\n",
    "#     if '=' in line:\n",
    "#         var, value = line.split('=', 1)\n",
    "#         os.environ[var] = value\n",
    "\n",
    "\n",
    "#unset http_proxy && unset https_proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d35bca-f2e1-4ba1-8d50-b5f4d6622d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = Retriever(embedder = 'BAAI/bge-m3',reranker = 'BAAI/bge-reranker-v2-m3',collection_name = 'sales_qa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27ce718-d078-4de6-b9e5-725e8ec3b075",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = BGEM3FlagModel('BAAI/bge-m3', cahche_dir = './autodl-tmp/.cache/huggingface/hub',use_fp16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb2b7f5-6be4-44bc-b592-6b98ae54359b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_path = '/root/autodl-tmp/.cache/huggingface/hub/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc29ce4-8281-4f9d-a040-0b5eb21f6a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "BGEM3FlagModel(embedder,use_fp16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70804d5-6752-4f3a-9ab8-d3361f3a6e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_id = 'ep-20250213200344-crq6r'\n",
    "#model_id = 'LLM-Research/Meta-Llama-3.1-8B-Instruct-AWQ-INT4'\n",
    "gen_llm = LLM(model_id,\n",
    "              api_key = os.getenv('ARK_API_KEY'),base_url = os.getenv('ARK_BASE_URL')\n",
    "             )\n",
    "#model_id = 'LLM-Research/Meta-Llama-3.1-8B-Instruct-AWQ-INT4'\n",
    "gen_llm('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce560172-e694-46c5-b5d6-1edba2836bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def set_proxy():\n",
    "    \n",
    "    # Run the bash command to source the network configuration and capture the proxy settings\n",
    "    result = subprocess.run(\n",
    "        'bash -c \"source /etc/network_turbo && env | grep proxy\"', \n",
    "        shell=True, capture_output=True, text=True\n",
    "    )\n",
    "\n",
    "    # Set the proxy environment variables from the command output\n",
    "    proxies = {}\n",
    "    for line in result.stdout.splitlines():\n",
    "        if '=' in line:\n",
    "            var, value = line.split('=', 1)\n",
    "            os.environ[var] = value\n",
    "            \n",
    "    # Yield control back to the block of code using the context manager\n",
    "    yield\n",
    "\n",
    "    # Restore the original proxy environment variables\n",
    "    for key, value in os.environ.items():\n",
    "        if 'proxy' in key:\n",
    "            os.environ.pop(key, None)  # Remove the key if it wasn't set originally\n",
    "with set_proxy():\n",
    "    print(1)\n",
    "proxies = {key: os.environ.get(key) for key in os.environ if 'proxy' in key.lower()}\n",
    "print(proxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f1de34-9fd2-4e6a-81e5-741324fe9030",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "?BGEM3FlagModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f0d1b3-585b-4c6f-8e7a-8142d11818fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_vars = \"\"\"\n",
    "HF_ENDPOINT=https://hf-mirror.com\n",
    "HF_HOME=/root/autodl-tmp/.cache/huggingface\n",
    "LMDEPLOY_USE_MODELSCOPE=True\n",
    "MODELSCOPE_CACHE=/root/autodl-tmp/.cache/modelscope/\n",
    "ARK_API_KEY= 'a2d08cdb-3d6f-42c0-bd4e-4b64ad505eb1'\n",
    "ARK_BASE_URL = 'https://ark.cn-beijing.volces.com/api/v3'\n",
    "retriever_path = '/root/autodl-tmp/.cache/huggingface/hub/'\n",
    "reranker_path = '/root/autodl-tmp/.cache/huggingface/hub/'\n",
    "vs_path = /root/data_disk/car/\n",
    "\"\"\"\n",
    "\n",
    "# Write to .env file\n",
    "with open(\".env\", \"w\") as f:\n",
    "    f.write(env_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6a2d19-dcc9-4fa6-b1f7-0a1089ef38d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf37e4c-a894-4ded-8335-13c8fe8e7054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049128e8-fea8-41b1-95e7-7715e26425f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba16ce2a-6400-43e1-a27d-03a7bee75af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,subprocess\n",
    "import sys\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fb06ad-24c7-4d09-bd2f-b1b81075f7b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import random\n",
    "import time\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(type=\"messages\")\n",
    "    msg = gr.Textbox()\n",
    "    clear = gr.Button(\"Clear\")\n",
    "\n",
    "    def user(user_message, history: list):\n",
    "        return \"\", history + [{\"role\": \"user\", \"content\": user_message}]\n",
    "        \n",
    "    def bot(history: list):\n",
    "        bot_message = random.choice([\"\"\"\"Hey! ðŸ˜Š Iâ€™m here to make your car-buying experience smooth and stress-free. Tell me a bit about what youâ€™re looking for, and Iâ€™ll get you started!\"\"\",\n",
    "                                    \"\"\"Hello and welcome! ðŸŽ‰ Ready to find your dream car? Let me guide you through our latest models, special offers, and financing options. What are you looking for?\"\"\",\n",
    "                                    \"\"\"\"Hey there! ðŸ‘‹ Excited to help you find the perfect car today! Whether itâ€™s something sleek, spacious, or sporty, Iâ€™ve got you covered. What kind of vehicle are you dreaming of?\"\"\"])\n",
    "        \n",
    "        history.append({\"role\": \"assistant\", \"content\": \"\"})\n",
    "        for character in bot_message:\n",
    "            history[-1]['content'] += character\n",
    "            time.sleep(0.05)\n",
    "            yield history\n",
    "\n",
    "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
    "        bot, chatbot, chatbot\n",
    "    )\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58922ded-cc10-4430-aee9-dd71e2ab513a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append('/root/data_disk/src')\n",
    "\n",
    "from retriever import Retriever\n",
    "from LLM_utils import LLM\n",
    "from prompt import generate_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab45046-c9fb-4d74-b2bf-218cc975685d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "query, history = 'i need a bmw', []\n",
    "\n",
    "# Initialize the Retriever with specific embedder and reranker\n",
    "retriever = Retriever(\n",
    "    embedder='BAAI/bge-m3',\n",
    "    reranker='BAAI/bge-reranker-v2-m3',\n",
    "    collection_name='sales_qa'\n",
    ")\n",
    "\n",
    "# Initialize the first LLM for query rewriting\n",
    "model_id = 'Qwen/Qwen2.5-3B-Instruct'\n",
    "rewriter = LLM(model_id)\n",
    "\n",
    "# Initialize the second LLM for response generation\n",
    "model_id = 'ep-20250213200344-crq6r'\n",
    "gen_llm = LLM(\n",
    "    model_id,\n",
    "    api_key=os.getenv('ARK_API_KEY'),  # Fetch API key from environment variables\n",
    "    base_url=os.getenv('ARK_BASE_URL'),\n",
    "    stream = True # Fetch base URL from environment variables\n",
    ")\n",
    "\n",
    "# Query rewriting\n",
    "rewrite_prompt = generate_prompt('rewrite', query, history, reranked_chunks=None)\n",
    "rewritten_query = rewriter(rewrite_prompt)\n",
    "\n",
    "# Retrieval\n",
    "recall_docs, reranked_chunks = retriever.retrieve(rewritten_query)\n",
    "\n",
    "# Response generation\n",
    "generation_prompt = generate_prompt('generate', query, history, reranked_chunks)\n",
    "response = gen_llm(generation_prompt)\n",
    "\n",
    "if isinstance(response, str):  \n",
    "    print(response)  # Directly print if it's a normal response\n",
    "else:  \n",
    "    for chunk in response:  # Iterate if it's a generator\n",
    "        print(chunk, end=\"\", flush=True)  # Print chunks continuously\n",
    "        \n",
    "# Update history\n",
    "history.append({\"User\": rewritten_query, \"Assistant\": response})\n",
    "\n",
    "print(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1cea72-941b-4dda-9ecd-d04cf3d707ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89251ec0-b269-41f3-93ef-2a6217988b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "how do I combine the code for RAG QA into the gradio UI integration code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc86ec4a-ef39-4c59-a5ac-74f0d38e0bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
